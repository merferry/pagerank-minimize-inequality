Algorithmic fairness has attracted significant attention in the past years \cite{tsioutsiouliklis2021fairness}. Given two groups of nodes, we say that a network is fair, if the nodes of the two groups hold equally central positions in the network \cite{pitoura2023pagerank}. Saxena et al. \cite{saxena2022fairsna} note that structural bias of social networks impact the fairness of a number of algorithms used for social-network analysis. Xie et al. \cite{xie2021fairrankvis} present a visual analysis framework for exploring multi-class bias in graph algorithms.

Tsioutsiouliklis et al. \cite{tsioutsiouliklis2021fairness} two classes of fair PageRank algorithms - fairness-sensitive PageRank and locally fair PageRank. They define a stronger fairness requirement, called universal personalized fairness, and show that locally fair algorithms also achieves this requirement. Krasanakis et al. \cite{krasanakis2021applying} present an algorithm for fair ranking with personalization, even when the personalization suffers from extreme bias while maintaining good rank quality. In another paper, Tsioutsiouliklis et al. \cite{tsioutsiouliklis2022link} provide formulae for estimating the role of existing edges in fairness, and for computing the effect of edge additions on fairness. They then propose linear time link recommendation algorithms for maximizing fairness.

% Oostenbach studies fairness in community detection. He proposes three fairness metric for community detection, and evaluates thirty community detection algorithms. He observes that spectral algorithms performs the worst in terms of fairness and accuracy, while other categories have one or more methods that perform well \cite{oostenbachfairness}.
